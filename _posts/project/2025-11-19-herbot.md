---
layout: post
title: Herbot
subtitle: Autonomous Herb Managing Robot
tags: [robot]
author: solgyu lee
category: project
mathjax: false
thumbnail-img: "/assets/img/Herbot/Herbot.jpeg"
---
Herbot is an autonomous herb management robot I developed as part of the "AI Embedded Programming" course. The system autonomously handles herb cutting and removes diseased leaves.

<video width="70%" controls>
  <source src="/assets/img/Herbot/Herbot-video.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

## Components

- Raspberry Pi 4
- Coral USB Accelerator
- NEMA 17 Stepper Motor
  - Conveyor belt, aluminum profile, carriage
- Linear Actuator
- DC Motor
- Pi Camera
- Servo Motor
- 12V to 6V Converter
- TMC2209 Driver
- 2x TB6612 Drivers

## Mechanical Design

The robot's manipulation system consists of four motors working together. A servo motor controls the gripper mechanism for cutting herbs. To enable full spatial movement, the gripper traverses along the Z-axis using a NEMA 17 stepper motor connected to a belt-driven conveyor system, while a linear actuator provides X-axis motion. Since plants require inspection from multiple angles, I integrated a DC motor beneath the plant pot to rotate it, allowing the robot to access all sides.

## Power and Motor Control

The system runs on three different motor types requiring distinct power requirements: the NEMA 17 (12V), linear actuator (6V), and DC motor (6V). I used a 12V power supply with three independent motor drivers: TMC2209 for the stepper motor, and two TB6612 drivers for the linear actuator and DC motor respectively. Since mixing 12V and 6V directly isn't feasible, I incorporated a DC-DC converter to step down 12V to 6V. Power distribution is managed through WAGO terminal blocks, which provide a clean, solder-free solution for splitting the supply into separate 12V and 6V rails.

## Motor Calibration

Hardware assembly was just the beginning. Each motor required careful calibration to determine operational parameters: belt travel range, step counts for precise positioning, gripper opening/closing angles, linear actuator movement increments, and optimal DC motor speed for stable plant rotation. I developed dedicated calibration routines for each motor to establish these values.

## Web Interface

<img src="/assets/img/Herbot/Herbot-web.PNG" alt="Herbot Web Interface" style="width:70%;">

To make the system more accessible, I built a web interface for Herbot. Users can view all captured images, access system logs, and remotely control the robot's operations. The core functionality is the "scan" feature, which systematically photographs the plant from multiple angles. I trained two vision models—one for herb species identification and another for disease detection—on my local machine, then deployed them to run on the Raspberry Pi 4 accelerated by the Coral USB device.

<img src="/assets/img/Herbot/Herbot-web-log.PNG" alt="Herbot Web Logs" style="width:70%;">

## Vision Models

The system relies on two specialized vision models working in tandem. The first model, Herbify, identifies herb species from 91 different classes including common varieties like Basil, Mint, and Turmeric. The second model uses the PlantDoc dataset to assess plant health, trained on 2,598 images covering 13 plant species with 28 distinct health conditions. I trained both models on my local machine, then compiled them for Edge TPU deployment to achieve real-time inference on the Raspberry Pi 4.

## Disease Detection Pipeline

The raw camera captures 640×480 images, which I preprocess by resizing to 224×224 and converting to RGB format. Each image passes through both models: Herbify outputs the herb species with confidence scores, while PlantDoc classifies the health status into one of 28 categories ranging from healthy leaves to specific diseases like early blight, rust, or leaf spot.

However, distinguishing between 28 disease types proved unnecessary for the robot's purpose. I simplified the classification into a binary decision: healthy or diseased. The system analyzes PlantDoc's output using keyword matching against disease indicators—terms like "blight", "spot", "rust", "scab", "mildew", "virus", "mold", "bacterial", and "spider". If the predicted class ends with "leaf" and contains none of these keywords, it's classified as healthy. Otherwise, if the confidence exceeds 60%, the system marks it for removal.

This approach filters out low-confidence detections below 40%, which typically represent background or empty space. Predictions between 40-60% are conservatively treated as healthy to avoid false positives. Only when the model shows strong confidence in detecting disease markers does the robot take action.

## Edge TPU Optimization

To achieve real-time performance on embedded hardware, I applied INT8 quantization to both models during the TensorFlow Lite conversion process. This reduces model size and computational requirements while maintaining accuracy. The Edge TPU compiler then generates optimized binaries that leverage the Coral accelerator's hardware capabilities.

The optimization delivers substantial speedup—inference time drops from 80-150ms on CPU to just 10-15ms on the Edge TPU for Herbify, and from 70-120ms to 5-12ms for PlantDoc. This acceleration enables the robot to scan multiple plant angles efficiently, processing each captured image in under 30ms total for both species identification and disease detection.

## Conclusion

This was an incredibly fun project, though not without its limitations. Budget constraints were significant while support from my department helped immensely, I still lacked both sufficient funding and time. As a result, Herbot has no proper housing. I improvised the base and rotary stage using a car air freshener box, and attached the camera and gripper to the carriage with adhesive and electrical tape. It looks crude, but the cost-efficiency was unbeatable.

This project taught me a critical lesson about cost-effectiveness in engineering. Most university coursework exists in an unrealistic bubble where practical constraints like budget and robustness simply don't matter. You're not building products for real users or dealing with real-world tradeoffs. But Herbot forced me to work within severe limitations(both financial and computational) and that made me think deeply about engineering compromises.

I realize now that this inexperience with real-world constraints was why my first drone project, Soltrone v1, failed. Back then, I naively thought I could just mount a flight controller, four propellers, and a Raspberry Pi together to create an autonomous drone. Reality hit hard with countless practical problems I hadn't anticipated. But the lessons from Herbot(understanding budget constraints, optimizing for limited resources, and making smart tradeoffs)will be invaluable for Soltrone v2.
